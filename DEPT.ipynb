{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e236f8-4d28-4e04-8082-c502ffdb2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a263072b-a7de-455f-811a-7024e2aba734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\awadh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\awadh\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DPTFeatureExtractor' from 'transformers' (D:\\Software_Install\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DPTFeatureExtractor, DPTForDepthEstimation\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create a DPT feature extractor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m DPTFeatureExtractor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntel/dpt-large\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'DPTFeatureExtractor' from 'transformers' (D:\\Software_Install\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import DPTFeatureExtractor, DPTForDepthEstimation\n",
    "\n",
    "# Create a DPT feature extractor\n",
    "feature_extractor = DPTFeatureExtractor.from_pretrained(\"Intel/dpt-large\")\n",
    "\n",
    "# Create a DPT depth estimation model\n",
    "model = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd6a17-eac5-4ca3-9f4e-11902e1a5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Specify the URL of the image to download\n",
    "url = 'https://img.freepik.com/free-photo/full-length-shot-pretty-healthy-young-lady-walking-morning-park-with-dog_171337-18880.jpg?w=360&t=st=1689213531~exp=1689214131~hmac=67dea8e3a9c9f847575bb27e690c36c3fec45b056e90a04b68a00d5b4ba8990e'\n",
    "\n",
    "# Download and open the image using PIL\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649961f8-acea-4707-b46b-35a38861864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Use torch.no_grad() to disable gradient computation\n",
    "with torch.no_grad():\n",
    "    # Pass the pixel values through the model\n",
    "    outputs = model(pixel_values)\n",
    "    # Access the predicted depth values from the outputs\n",
    "    predicted_depth = outputs.predicted_depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bbe78a-b050-4307-8e72-66dd1e8eb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Interpolate the predicted depth values to the original size\n",
    "prediction = torch.nn.functional.interpolate(\n",
    "    predicted_depth.unsqueeze(1),\n",
    "    size=image.size[::-1],\n",
    "    mode=\"bicubic\",\n",
    "    align_corners=False,\n",
    ").squeeze()\n",
    "\n",
    "# Convert the interpolated depth values to a numpy array\n",
    "output = prediction.cpu().numpy()\n",
    "\n",
    "# Scale and format the depth values for visualization\n",
    "formatted = (output * 255 / np.max(output)).astype('uint8')\n",
    "\n",
    "# Create an image from the formatted depth values\n",
    "depth = Image.fromarray(formatted)\n",
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab29bc95-7517-487c-8f64-0a0dfa762b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Installing Transformer library\n",
    "!pip install -q datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48613db9-8a9e-4894-b622-4449cddda5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and modules\n",
    "from transformers import AutoImageProcessor, DPTForDepthEstimation\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf98c73-e2fe-400a-a0ac-2562c538790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL to fetch the image from the COCO dataset\n",
    "url = \"http://farm1.staticflickr.com/230/499938318_cdadac6a73_z.jpg\"\n",
    "\n",
    "# Open the image from the URL using PIL (Python Imaging Library)\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c534f2-dbab-4d33-811b-5828e0253449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the pre-trained AutoImageProcessor and DPTForDepthEstimation models\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"Intel/dpt-large\")\n",
    "model = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c549d-5ac8-41aa-8a91-ff557e6df60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the image for the model by encoding it with the image processor\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# Perform depth estimation on the image using the DPTForDepthEstimation model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predicted_depth = outputs.predicted_depth\n",
    "\n",
    "# Interpolate the predicted depth to the original image size\n",
    "prediction = torch.nn.functional.interpolate(\n",
    "    predicted_depth.unsqueeze(1),\n",
    "    size=image.size[::-1],  # Resizing to the original size of the image\n",
    "    mode=\"bicubic\",\n",
    "    align_corners=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd063d-f869-453c-bc53-c519d358d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the prediction\n",
    "output = prediction.squeeze().cpu().numpy()\n",
    "formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n",
    "depth = Image.fromarray(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0133040-b814-4857-aa40-08b36ae170b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
